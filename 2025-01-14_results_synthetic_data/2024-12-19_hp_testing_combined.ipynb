{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b86fcd4b-4129-470f-937f-de68f3a5834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c641d68f-2d99-42aa-8643-76d0fdffd21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from wassa.wassa_plots import plot_results_std, plot_SM, plot_colored_raster\n",
    "from wassa.dataset_generation import sm_generative_model, generate_dataset\n",
    "from wassa.wassa_utils import train_and_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "375c71f3-ca6f-4b0f-aafd-446224e2142e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "date = '2024_12_10'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef015448-f9cc-4099-aeb0-a01ee5e554bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_parameters():\n",
    "    seed = 666\n",
    "    \n",
    "    N_pre = 100 # number of neurons3490735590457916\n",
    "    N_timesteps = 255 # number of timesteps for the raster plot (in ms)\n",
    "    N_samples = 100 # total number of samples in the dataset\n",
    "\n",
    "    N_delays = 51 # number of timesteps in spiking motifs, must be a odd number for convolutions\n",
    "    N_SMs = 4 # number of structured spiking motifs\n",
    "    N_involved = N_pre*torch.ones(N_SMs) # number of neurons involved in the spiking motif\n",
    "    avg_fr = 20 # average firing rate of the neurons (in Hz)\n",
    "    std_fr = .1 # standard deviation for the firing rates of the different neurons\n",
    "    frs = torch.normal(avg_fr, std_fr, size=(N_pre,)).abs()\n",
    "    freq_sms = 16*torch.ones(N_SMs) # frequency of apparition of the different spiking motifs (in Hz)\n",
    "    overlapping_sms = False # possibility to have overlapping sequences\n",
    "\n",
    "    temporal_jitter = .1 # temporal jitter for the spike generation in motifs\n",
    "    dropout_proba = 0 # probabilistic participations of the different neurons to the spiking motif\n",
    "    additive_noise = .1 # percentage of background noise/spontaneous activity\n",
    "    warping_coef = 1 # coefficient for time warping\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return f'{self.N_pre}_{self.N_delays}_{self.N_SMs}_{self.N_timesteps}_{self.N_samples}_{self.N_involved.mean()}_{self.avg_fr}_{self.freq_sms.mean()}_{self.overlapping_sms}_{self.temporal_jitter}_{self.dropout_proba}_{self.additive_noise}_{self.warping_coef}_{self.seed}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797d3546-81d7-47bb-ae74-abd2f1961dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_iter = 5\n",
    "seeds = torch.arange(N_iter)\n",
    "lambdaz = [0, .0001, .0005, .001, .005, .01, .05, .1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7ae90d4-2a9e-4979-b50e-f53e50fe0425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_as_a_function_of_lambda(world_parameters, training_parameters, date, lambdaz, N_iter = 5, seeds = None, device='cpu'):\n",
    "    \n",
    "    results = torch.zeros([3,N_iter,len(lambdaz),6])\n",
    "    if seeds is not None:\n",
    "        assert seeds.size(0)==N_iter\n",
    "    else:\n",
    "        seeds = torch.randint(1000,[N_iter])\n",
    "    \n",
    "    params_mse = training_parameters()\n",
    "    params_emd = training_parameters()\n",
    "    params_emd.loss_type = 'emd'\n",
    "    \n",
    "    file_name = f'results/{date}_performance_as_a_function_of_lambda_{world_parameters().get_parameters()}_{params_emd.get_parameters()}_{lambdaz[0]}_{lambdaz[-1]}'\n",
    "    print(file_name)\n",
    "    \n",
    "    if os.path.isfile(file_name):\n",
    "        results, lambdaz = torch.load(file_name, map_location='cpu')\n",
    "    else:\n",
    "        pbar = tqdm(total=len(lambdaz)*N_iter)\n",
    "        for i in range(N_iter):\n",
    "            world_parameters.seed = seeds[i]\n",
    "            for ind_f, lambda_ in enumerate(lambdaz):\n",
    "                params_mse.lambda_ = lambda_\n",
    "                params_emd.lambda_ = lambda_\n",
    "                sm, trainset_input, trainset_output, testset_input, testset_output = generate_dataset(world_parameters,verbose = False,device=device)\n",
    "                results[0,i,ind_f,0], results[0,i,ind_f,1], results[0,i,ind_f,2], results[0,i,ind_f,3], results[0,i,ind_f,4], results[0,i,ind_f,5], _, _ = train_and_plot(sm, trainset_input, testset_input, testset_output, [params_mse], date, iteration = i, device=device)\n",
    "                results[1,i,ind_f,0], results[1,i,ind_f,1], results[1,i,ind_f,2], results[1,i,ind_f,3], results[1,i,ind_f,4], results[1,i,ind_f,5], _, _ = train_and_plot(sm, trainset_input, testset_input, testset_output, [params_emd], date, iteration = i, device=device)\n",
    "                results[2,i,ind_f,0], results[2,i,ind_f,1], results[2,i,ind_f,2], results[2,i,ind_f,3], results[2,i,ind_f,4], results[2,i,ind_f,5], _, _ = train_and_plot(sm, trainset_input, testset_input, testset_output, [params_emd,params_mse], date, iteration = i, device=device)\n",
    "                pbar.update(1)\n",
    "\n",
    "        pbar.close()\n",
    "        torch.save([results, lambdaz], file_name)\n",
    "    return results, lambdaz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48395831-afed-41e5-8095-6d06c417ddb5",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning: optimal lambda for max cross correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55148c3a-a412-49b7-98b9-c84542c05334",
   "metadata": {},
   "outputs": [],
   "source": [
    "class training_parameters:\n",
    "    kernel_size = (dataset_parameters.N_SMs, dataset_parameters.N_pre, dataset_parameters.N_delays)\n",
    "    loss_type = 'mse'\n",
    "    N_learnsteps = 1000\n",
    "    learning_rate = .001\n",
    "    penalty_type = 'max_cc'\n",
    "    smoothwind = 40\n",
    "    lambda_ = .0005\n",
    "    batch_size = None\n",
    "    output = 'linear' \n",
    "    do_bias = True \n",
    "    zeros = 'ignore'\n",
    "    wass_order = 1\n",
    "    weight_init = None\n",
    "    if not penalty_type:\n",
    "        lambda_ = 0\n",
    "    elif penalty_type[:8] != 'smoothed': \n",
    "        smoothwind = 0\n",
    "    if lambda_ == 0:\n",
    "        penalty_type = None\n",
    "    def get_parameters(self):\n",
    "        name = f'{self.loss_type}_{self.output}_{self.penalty_type}_{self.do_bias}_{self.kernel_size}_{self.N_learnsteps}_{self.learning_rate}_{self.lambda_}_{self.batch_size}_{self.smoothwind}'\n",
    "        if self.loss_type == 'emd':\n",
    "            name += f'_{self.zeros}_{self.wass_order}'\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bad867-45ca-40b0-b36b-abb7f3f5df4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/2024_12_10_performance_as_a_function_of_lambda_100_51_4_255_100_100.0_20_16.0_False_0.1_0_0.1_1_666_emd_linear_max_cc_True_(4, 100, 51)_1000_0.001_0.0005_None_0_ignore_1_0_0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▍                                                                                                                                            | 2/40 [00:11<03:16,  5.18s/it]"
     ]
    }
   ],
   "source": [
    "results, lambdaz = performance_as_a_function_of_lambda(dataset_parameters, training_parameters, date, lambdaz, N_iter = N_iter, seeds = seeds, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2df2d86-be35-4732-b2cd-cb47ba6e0847",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_metrics = ['factors similarity', 'kernels similarity', 'mean timings\\nsimilarity', 'MSE', 'EMD', 'EMD means']\n",
    "name_methods = ['MSE', 'EMD', 'combined']\n",
    "colors = ['darkolivegreen','blue', 'orangered']\n",
    "xlabel = 'temporal jitter'\n",
    "\n",
    "results = results.cpu()\n",
    "for i in range(len(name_metrics)):\n",
    "    fig, ax = plt.subplots()\n",
    "    for m in range(len(name_methods)):\n",
    "        ax = plot_results_std(ax,results[m,:,:,i],lambdaz,xlabel,name_metrics[i],name_methods[m],colors[m], logplot=True)\n",
    "        if i<3:\n",
    "            print(f'for {name_metrics[i]} with AE trained with {name_methods[m]}')\n",
    "            val_max = max(results[m,:,:,i].mean(axis=0))\n",
    "            ind_max = np.argmax(results[m,:,:,i].mean(axis=0))\n",
    "            print(f'{val_max} is the max at lambda = {lambdaz[ind_max]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c8834b-a069-45a9-8efc-947f0688175c",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning: optimal lambda for cross correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f8229-d9ee-476b-8d4c-ca8db59323c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters.penalty_type = 'cc'\n",
    "results, lambdaz = performance_as_a_function_of_lambda(dataset_parameters, training_parameters, date, lambdaz, N_iter = N_iter, seeds = seeds, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a080c-73e5-4eb5-9561-5486ab9c3e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.cpu()\n",
    "for i in range(len(name_metrics)):\n",
    "    fig, ax = plt.subplots()\n",
    "    for m in range(len(name_methods)):\n",
    "        ax = plot_results_std(ax,results[m,:,:,i],lambdaz,xlabel,name_metrics[i],name_methods[m],colors[m], logplot=True)\n",
    "        if i<3:\n",
    "            print(f'for {name_metrics[i]} with AE trained with {name_methods[m]}')\n",
    "            val_max = max(results[m,:,:,i].mean(axis=0))\n",
    "            ind_max = np.argmax(results[m,:,:,i].mean(axis=0))\n",
    "            print(f'{val_max} is the max at lambda = {lambdaz[ind_max]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed58a6dd-c6c6-4f95-95c1-bc123e8efdcf",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning: optimal lambda for smoothed orthogonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae344dbc-51b8-4963-8e15-73f2275e8575",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters.penalty_type = 'smoothed_orthogonality'\n",
    "results, lambdaz = performance_as_a_function_of_lambda(dataset_parameters, training_parameters, date, lambdaz, N_iter = N_iter, seeds = seeds, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88c5c2-7765-4699-a2f3-892dc02a7e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.cpu()\n",
    "for i in range(len(name_metrics)):\n",
    "    fig, ax = plt.subplots()\n",
    "    for m in range(len(name_methods)):\n",
    "        ax = plot_results_std(ax,results[m,:,:,i],lambdaz,xlabel,name_metrics[i],name_methods[m],colors[m], logplot=True)\n",
    "        if i<3:\n",
    "            print(f'for {name_metrics[i]} with AE trained with {name_methods[m]}')\n",
    "            val_max = max(results[m,:,:,i].mean(axis=0))\n",
    "            ind_max = np.argmax(results[m,:,:,i].mean(axis=0))\n",
    "            print(f'{val_max} is the max at lambda = {lambdaz[ind_max]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137e058b-fd58-4e11-8d60-46fc8c6a2c93",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning: optimal lambda for kernels' orthogonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e8d00-827e-4bc7-8924-ce4cf081f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters.penalty_type = 'kernels_orthogonality'\n",
    "results, lambdaz = performance_as_a_function_of_lambda(dataset_parameters, training_parameters, date, lambdaz, N_iter = N_iter, seeds = seeds, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556c5c7-f8e3-46ad-9ebf-2ebbacc527ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.cpu()\n",
    "for i in range(len(name_metrics)):\n",
    "    fig, ax = plt.subplots()\n",
    "    for m in range(len(name_methods)):\n",
    "        ax = plot_results_std(ax,results[m,:,:,i],lambdaz,xlabel,name_metrics[i],name_methods[m],colors[m], logplot=True)\n",
    "        if i<3:\n",
    "            print(f'for {name_metrics[i]} with AE trained with {name_methods[m]}')\n",
    "            val_max = max(results[m,:,:,i].mean(axis=0))\n",
    "            ind_max = np.argmax(results[m,:,:,i].mean(axis=0))\n",
    "            print(f'{val_max} is the max at lambda = {lambdaz[ind_max]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b434c3e1-2706-4c29-ba05-a47d929d49b5",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning: optimal lambda for sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6392a7-7fee-4fbe-ae05-7c04b1a11de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters.penalty_type = 'sparsity'\n",
    "results, lambdaz = performance_as_a_function_of_lambda(dataset_parameters, training_parameters, date, lambdaz, N_iter = N_iter, seeds = seeds, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782d1111-c694-4ecc-ab0e-4afaa3135e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.cpu()\n",
    "for i in range(len(name_metrics)):\n",
    "    fig, ax = plt.subplots()\n",
    "    for m in range(len(name_methods)):\n",
    "        ax = plot_results_std(ax,results[m,:,:,i],lambdaz,xlabel,name_metrics[i],name_methods[m],colors[m], logplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc3092f-b721-4b7a-8a8e-85837b8d2c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqnmf import seqnmf\n",
    "from wassa import WassA\n",
    "from wassa_metrics import get_similarity\n",
    "\n",
    "def performance_seqnmf_as_a_function_of_lambda(world_parameters, training_parameters, date, lambdaz, N_iter = 5, seeds = None, device='cpu'):\n",
    "    \n",
    "    results = torch.zeros([1,N_iter,len(lambdaz),6])\n",
    "    if seeds is not None:\n",
    "        assert seeds.size(0)==N_iter\n",
    "    else:\n",
    "        seeds = torch.randint(1000,[N_iter])\n",
    "    \n",
    "    params_mse = training_parameters()\n",
    "    params_emd = training_parameters()\n",
    "    params_emd.loss_type = 'emd'\n",
    "    file_name = f'results/{date}_performance_seqnmf_as_a_function_of_lambda{world_parameters().get_parameters()}_{params_emd.get_parameters()}_{lambdaz[0]}_{lambdaz[-1]}'\n",
    "    print(file_name)\n",
    "    \n",
    "    if os.path.isfile(file_name):\n",
    "        results, lambdaz = torch.load(file_name, map_location='cpu')\n",
    "    else:\n",
    "        pbar = tqdm(total=len(lambdaz)*N_iter)\n",
    "        for i in range(N_iter):\n",
    "            world_parameters.seed = seeds[i]\n",
    "            for ind_f, lambda_ in enumerate(lambdaz):\n",
    "                sm, trainset_input, trainset_output, testset_input, testset_output = generate_dataset(world_parameters,verbose = False,device=device)\n",
    "                path_seqnmf_ = f'results/{date}_seqnmf_{world_parameters.get_parameters()}_{lambda_}'\n",
    "                if os.path.isfile(path_seqnmf_):\n",
    "                    W, H, cost, loadings, power = torch.load(path_seqnmf_)\n",
    "                else:\n",
    "                    seqnmf_input = torch.cat([trainset_input[i] for i in range(trainset_input.shape[0])],dim=-1).to('cpu')\n",
    "                    W, H, cost, loadings, power = seqnmf(seqnmf_input, K=world_parameters.N_SMs, L=world_parameters.N_delays, Lambda=lambda_, max_iter=1000)\n",
    "                    torch.save([W, H, cost, loadings, power],path_seqnmf_)\n",
    "\n",
    "                learnt_kernels = WassA(sm.SMs.shape,weight_init=torch.tensor(W.swapaxes(0,1),dtype=torch.float32),device=device)\n",
    "                if np.isnan(W).sum()==0:\n",
    "                    results[0,i,ind_f,0], results[0,i,ind_f,1], results[0,i,ind_f,2], results[0,i,ind_f,3], results[0,i,ind_f,4], results[0,i,ind_f,5] = get_similarity(sm,learnt_kernels,testset_input,device=device)\n",
    "                \n",
    "                pbar.update(1)\n",
    "\n",
    "        pbar.close()\n",
    "        torch.save([results, lambdaz], file_name)\n",
    "    return results, lambdaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73793f8-5e11-4961-bca0-9d36e7943a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, lambdaz = performance_seqnmf_as_a_function_of_lambda(dataset_parameters, training_parameters, date, lambdaz, N_iter = N_iter, seeds = seeds, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdec2a8-e194-4d4c-857b-51bcd74df811",
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_types = ['max_cc', 'cc', 'smoothed_orthogonality', 'kernels_orthogonality']\n",
    "\n",
    "results = results.cpu()\n",
    "fig, ax = plt.subplots(3,4, figsize = (20,20))\n",
    "for i in range(3):\n",
    "    for p, pen_type in enumerate(pen_types):\n",
    "        for m in range(len(name_methods)):\n",
    "            lambdaz = lambdaz_both[lambdaz_ind[p]]\n",
    "            ax[i,p] = plot_results_std(ax[i,p],results[m,:,p,:,i],lambdaz,xlabel,name_metrics[i],name_methods[m]+pen_type,colors[m], logplot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6579c7de-f6d8-424d-b97a-326b267da128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6f3c9-feb1-4a17-906a-af53f8f30664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
