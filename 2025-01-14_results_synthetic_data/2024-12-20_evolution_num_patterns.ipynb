{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2443c9af-2e03-4f0a-8d2e-478e8df8151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e50bd-1b65-4942-adc7-f4beeefd3c0d",
   "metadata": {},
   "source": [
    "# Training as a function of the number of patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "366dd262-996d-494d-b283-4a95f56c0927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wassa.wassa_plots import plot_results_std, plot_SM, plot_colored_raster\n",
    "from wassa.dataset_generation import sm_generative_model, generate_dataset\n",
    "from wassa.wassa_utils import performance_as_a_function_of_number_of_motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "848910ac-dbc4-4a1a-bc9e-c9e37181116a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "date = '2024_01_15'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb3ebdc-61f5-45fb-b460-4e816ff69375",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_parameters():\n",
    "    seed = 666\n",
    "    \n",
    "    N_pre = 100 # number of neurons\n",
    "    N_timesteps = 255 # number of timesteps for the raster plot (in ms)\n",
    "    N_samples = 100 # total number of samples in the dataset\n",
    "\n",
    "    N_delays = 51 # number of timesteps in spiking motifs, must be a odd number for convolutions\n",
    "    N_SMs = 1 # number of structured spiking motifs\n",
    "    N_involved = N_pre*torch.ones(N_SMs) # number of neurons involved in the spiking motif\n",
    "    avg_fr = 20 # average firing rate of the neurons (in Hz)\n",
    "    std_fr = .1 # standard deviation for the firing rates of the different neurons\n",
    "    frs = torch.normal(avg_fr, std_fr, size=(N_pre,)).abs()\n",
    "    freq_sms = 16*torch.ones(N_SMs) # frequency of apparition of the different spiking motifs (in Hz)\n",
    "    overlapping_sms = False # possibility to have overlapping sequences\n",
    "\n",
    "    temporal_jitter = .1 # temporal jitter for the spike generation in motifs\n",
    "    dropout_proba = 0 # probabilistic participations of the different neurons to the spiking motif\n",
    "    additive_noise = .1 # percentage of background noise/spontaneous activity\n",
    "    warping_coef = 1 # coefficient for time warping\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return f'{self.N_pre}_{self.N_delays}_{self.N_SMs}_{self.N_timesteps}_{self.N_samples}_{self.N_involved.mean()}_{self.avg_fr}_{self.freq_sms.mean()}_{self.overlapping_sms}_{self.temporal_jitter}_{self.dropout_proba}_{self.additive_noise}_{self.warping_coef}_{self.seed}'\n",
    "\n",
    "torch.serialization.add_safe_globals([dataset_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e082132a-420a-4922-bc4b-7ff229b74eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class training_parameters:\n",
    "    kernel_size = (dataset_parameters.N_SMs, dataset_parameters.N_pre, dataset_parameters.N_delays)\n",
    "    loss_type = 'mse'\n",
    "    N_learnsteps = 1000\n",
    "    learning_rate = .001\n",
    "    penalty_type = 'smoothed_orthogonality'\n",
    "    smoothwind = 40\n",
    "    lambda_ = .014\n",
    "    batch_size = None\n",
    "    output = 'linear' \n",
    "    do_bias = True \n",
    "    zeros = 'ignore'\n",
    "    wass_order = 1\n",
    "    weight_init = None\n",
    "    if not penalty_type: \n",
    "        lambda_ = 0\n",
    "    elif penalty_type[:8] != 'smoothed': \n",
    "        smoothwind = 0\n",
    "    if lambda_ == 0:\n",
    "        penalty_type = None\n",
    "    def get_parameters(self):\n",
    "        name = f'{self.loss_type}_{self.output}_{self.penalty_type}_{self.do_bias}_{self.kernel_size}_{self.N_learnsteps}_{self.learning_rate}_{self.lambda_}_{self.batch_size}_{self.smoothwind}'\n",
    "        if self.loss_type == 'emd':\n",
    "            name += f'_{self.zeros}_{self.wass_order}'\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "701ece58-4e93-4d6a-81d2-435d30f63244",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_mse = training_parameters()\n",
    "params_emd = training_parameters()\n",
    "params_emd.loss_type = 'emd'\n",
    "params_emd.penalty_type = 'kernels_orthogonality'\n",
    "params_emd.lambda_ = .0014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168a340d-0048-4953-b02b-1678c606276b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/2024_01_15_performance_as_a_function_of_number_of_motifs_100_51_1_255_100_100.0_20_16.0_False_0.1_0_0.1_1_666_emd_linear_kernels_orthogonality_True_(1, 100, 51)_1000_0.001_0.0014_None_40_ignore_1_1_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antoineg/miniconda3/envs/wassa/lib/python3.12/site-packages/wassa-1.0-py3.12.egg/wassa/wassa_utils.py:22: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /opt/conda/conda-bld/pytorch_1729647175880/work/aten/src/ATen/native/Convolution.cpp:1036.)\n",
      "  2%|███▎                                                                                                                                               | 2/90 [1:42:04<69:02:20, 2824.32s/it]"
     ]
    }
   ],
   "source": [
    "N_iter = 10\n",
    "seeds = torch.arange(0,N_iter)\n",
    "num_patterns = torch.arange(1,10)\n",
    "results, num_patterns = performance_as_a_function_of_number_of_motifs(dataset_parameters, params_emd, params_mse, date, num_patterns, N_iter = N_iter, seeds = seeds, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce3a5d-e3e5-4054-969c-e620e4c6018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_std(ax, results, coefs, xlabel, ylabel, legend, color, do_ylabel, ymax=None, ymin=None, do_legend=False, logplot=False, quantile=False):\n",
    "     \n",
    "    mean_, std_ = results.mean(axis=0), results.std(axis=0)\n",
    "    \n",
    "    if quantile: \n",
    "        q5 = results.quantile(.1,axis=0)\n",
    "        q95 = results.quantile(.9,axis=0)\n",
    "\n",
    "    if quantile:\n",
    "        bottom_ = q5\n",
    "    elif ymin is not None:\n",
    "        bottom_ = np.maximum(mean_ - std_, ymin*np.ones([len(mean_)]))\n",
    "    else:\n",
    "        bottom_ = mean_ - std_\n",
    "        \n",
    "    if quantile:\n",
    "        top_ = q95\n",
    "    elif ymax is not None:\n",
    "        top_= np.minimum(mean_ + std_, ymax*np.ones([len(mean_)]))\n",
    "    else:\n",
    "        top_ = mean_ + std_\n",
    "\n",
    "    if logplot:\n",
    "        ax.semilogx(coefs, mean_, '.',color=color, label=legend)\n",
    "    else:\n",
    "        ax.plot(coefs, mean_, '.',color=color, label=legend)\n",
    "    ax.fill_between(coefs, bottom_, top_, facecolor=color, edgecolor=None, alpha=.3)\n",
    "\n",
    "    ax.set_ylim(ymin,ymax)\n",
    "    \n",
    "    if xlabel: \n",
    "        ax.set_xlabel(xlabel, fontsize=14)\n",
    "    else: \n",
    "        ax.set_xticks([])\n",
    "    if do_ylabel:\n",
    "        ax.set_ylabel('similarity valuseu jorge albume', fontsize=14)\n",
    "    else: \n",
    "        ax.set_yticks([])\n",
    "    ax.set_title(ylabel, fontsize=16)\n",
    "    if do_legend: \n",
    "        ax.legend(fontsize=12);\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b59cec-8a6b-4b00-aac4-61d42614702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "name_metrics = ['factors similarity', 'kernels similarity', 'mean timings similarity']\n",
    "name_methods = ['MSE', 'EMD', 'combined']\n",
    "colors = ['darkolivegreen','blue','orangered']\n",
    "xlabel = '# spiking motifs'\n",
    "\n",
    "results = results.cpu()\n",
    "fig, ax = plt.subplots(1,3, figsize=(16,5))\n",
    "for i in range(len(name_metrics)):\n",
    "    for m in range(len(name_methods)):\n",
    "        if i==0:\n",
    "            do_ylabel = True\n",
    "        else:\n",
    "            do_ylabel = False\n",
    "        ax[i] = plot_results_std(ax[i],results[m,:,:,i],num_patterns,xlabel,name_metrics[i],name_methods[m],colors[m],ymax=1,ymin=0,do_ylabel=do_ylabel,quantile=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31fb961a-b31f-4cc2-8f76-7f9b1ff98bca",
   "metadata": {},
   "source": [
    "fig.tight_layout()\n",
    "fig.savefig('../figures/results_motifs.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f664077-1137-428d-9eec-0111db1c3c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
